{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "narrative-watershed",
   "metadata": {},
   "source": [
    "# Loss Function: \n",
    "\n",
    "La Loss Function o Cost Function es la funcion que elijamos para calcular cómo está performando nuestro modelo. Esta función mapea los valores de las variables del modelo con un número real que representa el \"costo\" que esa version del modelo tiene respecto a los valores desables. Idealmente, el objetivo del modelo es optimizar el valor de los weights and biases hasta obtener el costo más bajo, para ello, \n",
    "\n",
    "Intuitivamente diría que esta función se utiliza con modelos supervisado porque entre sus parametros recibe los targets o labels del modelo, pero esto habría que revisarlo mejor.\n",
    "\n",
    "En la bibliografía e incluso en pytorch, esta función recibe distintos nombre:\n",
    "\n",
    "- error function\n",
    "- criterion function\n",
    "- cost function\n",
    "- objective function\n",
    "- loss function\n",
    "\n",
    "Si bien, por regla general todas la denominaciones hacen referencia a lo mismo, esto no es estrictamente así en todos los escenarios.\n",
    "\n",
    "Una diferencia entre funciones cost, loss y objective esta en este [comentario de stack exchange](https://stats.stackexchange.com/questions/179026/objective-function-cost-function-loss-function-are-they-the-same-thing)\n",
    "\n",
    "La noción de 'criterion' y la idea general de función loss que viene del decision theory se me escapa bastante.\n",
    "\n",
    "\n",
    "-------------------------------------------------\n",
    "<sub>To do: explicar estas diferencias de denominación</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-completion",
   "metadata": {},
   "source": [
    "## Por qué funciona?\n",
    "\n",
    "Ok, pero cómo saber qué cambios debemos hacer en nuestros w&b, que recordemos se inicializaorn con valores random, para obtener el resultado más bajo de nuestra función loss? \n",
    "\n",
    "Dejemos que alguien lo explique mejor, como, por ejemplo, este [post de kaggle](https://www.kaggle.com/erdemuysal/linear-regression-from-scratch-and-with-pytorch)\n",
    "\n",
    "\"The loss is a quadratic function of our weights and biases, and our objective is to find the set of weights where the loss is the lowest. If we plot a graph of the loss w.r.t any individual weight or bias element, it will look like the figure shown below. A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases.\n",
    "\n",
    "<img src=\"LOSSIMAGE.png\">\n",
    "\n",
    "\n",
    "The increase or decrease in loss by changing a weight element is proportional to the value of the gradient of the loss w.r.t. that element. This forms the basis for the optimization algorithm that we'll use to improve our model.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-focus",
   "metadata": {},
   "source": [
    "# Distintas Loss Functions y su aplicación\n",
    "\n",
    "## Problemas de regresión \n",
    "\n",
    "Para problemas de regresión[<sup>1</sup>](#fn1), una de las funciones loss más usadas es el Mean Squared Error, pero también pueden aplicarse  Mean Absolute Error u otras y su elección depende de la distribución de los datos, la presencia de outliers, factores que habría que analizar al momento de tener un corpus.\n",
    "\n",
    "\n",
    "### Mean Squared Error Loss\n",
    "\n",
    "Esta función toma los valores esperados (y) y los valores de la prediccion (y_hat) y suma el total de sus distancias cuadradas. El total de esta suma es promediado por el numero de ejemplos.\n",
    "\n",
    "\n",
    "<img src=\"MSEL.png\">\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "<sub>[<sup id=\"fn1\">1</sup>](#fn1-back)Un problema de regresión es aquel cuyas variables de salida (o outputs) son valores reales o continuos, como 'salario', 'peso', 'costo de una propiedad'.</span></sub>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "grand-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  tensor([[ 0.7359,  0.0151, -0.5575, -0.0653,  1.9399],\n",
      "        [-0.0838, -1.0402, -1.4656,  0.7395, -0.9094],\n",
      "        [-1.3699,  0.0111, -0.3795, -0.0299,  0.2474]], requires_grad=True)\n",
      "targets:  tensor([[-0.2327, -0.5158, -1.0786, -1.4120, -1.2959],\n",
      "        [ 1.3439,  0.0142,  0.3374, -1.5199,  0.4060],\n",
      "        [ 1.9622,  0.0635, -1.2803, -0.1006, -0.4490]])\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "#Implementación en Pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "outputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch.randn(3, 5)\n",
    "loss = mse_loss(outputs, targets)\n",
    "print('output: ', outputs)\n",
    "print('targets: ', targets)\n",
    "print('-------------------')\n",
    "#print('loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "seven-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_se tensor([0., 0., 0., 0., 0.])\n",
      "se tensor([ 0.9381,  0.2819,  0.2716,  1.8137, 10.4705], grad_fn=<PowBackward0>)\n",
      "sum_se tensor([ 0.9381,  0.2819,  0.2716,  1.8137, 10.4705], grad_fn=<AddBackward0>)\n",
      "se tensor([2.0383, 1.1118, 3.2508, 5.1047, 1.7302], grad_fn=<PowBackward0>)\n",
      "sum_se tensor([ 2.9764,  1.3937,  3.5224,  6.9185, 12.2007], grad_fn=<AddBackward0>)\n",
      "se tensor([1.1103e+01, 2.7474e-03, 8.1147e-01, 5.0023e-03, 4.8500e-01],\n",
      "       grad_fn=<PowBackward0>)\n",
      "sum_se tensor([14.0795,  1.3964,  4.3338,  6.9235, 12.6857], grad_fn=<AddBackward0>)\n",
      "end tensor([14.0795,  1.3964,  4.3338,  6.9235, 12.6857], grad_fn=<AddBackward0>)\n",
      "tensor(39.4189, grad_fn=<SumBackward0>)\n",
      "tensor(2.6279, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Cuenta propia para ver cómo funciona\n",
    "\n",
    "sum_se = torch.zeros(5)\n",
    "print('sum_se', sum_se)\n",
    "for i in zip(targets, outputs):\n",
    "    se = (i[0] - i[1]) ** 2\n",
    "    print('se', se)\n",
    "    sum_se += se\n",
    "    print('sum_se', sum_se)\n",
    "print('end', sum_se)\n",
    "    \n",
    "sum_num = torch.sum(sum_se)\n",
    "print(sum_num)\n",
    "\n",
    "mse = sum_num / 15\n",
    "#mse = sum_num / len(targets) descomentar para ver el resultado de interpretar N como len de targets en vez de MxN\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-species",
   "metadata": {},
   "source": [
    "### Por qué 15?\n",
    "\n",
    "Cuando tomé la primera descripción de la función 'no me daban los números' y mi resultado no era el mismo que el de aplicar la función de pytorch, hasta que encontré esta descripción que hace explicito que los valores involucrados no son puntos sino matrices mxn.\n",
    "\n",
    "<img src=\"MSELMxN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-dryer",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regression with california housing dataset (default available in colab)\n",
    "\n",
    "Con este ejemplo quise ilustrar de manera simple el uso de MSE en un modelo entrenado con pytorch. De ningún modo este modelo funciona, ni en este ni en ningún otro data set de regresión, pero se podria acomodar para que lo haga, empezando por agregar un DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "comparable-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "every-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01 \n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "flush-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
       "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
       "2    -114.56     33.69                17.0        720.0           174.0   \n",
       "3    -114.57     33.64                14.0       1501.0           337.0   \n",
       "4    -114.57     33.57                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0         1.4936             66900.0  \n",
       "1      1129.0       463.0         1.8200             80100.0  \n",
       "2       333.0       117.0         1.6509             85700.0  \n",
       "3       515.0       226.0         3.1917             73400.0  \n",
       "4       624.0       262.0         1.9250             65500.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./california_housing_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "persistent-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean empty values and inf\n",
    "train_df.replace([np.inf, -np.inf], np.nan)  # Replace inf values with NaNs\n",
    "train_df.dropna(inplace=True)  # Drop NaN values from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ecological-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17000, 8), (17000, 1))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs, targets\n",
    "# Convert from Pandas dataframe to numpy arrays\n",
    "inputs = train_df.drop(['median_house_value'], axis=1).to_numpy()  # Drop TARGET_COLUMN since it is target, can not be used as input\n",
    "targets = train_df[['median_house_value']].to_numpy()# Drop 'ocean_proximity' since it is not numerical value\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "acoustic-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "inputs = inputs.float()\n",
    "targets = torch.from_numpy(targets)\n",
    "targets = targets.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "thirty-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "communist-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linearRegression(8, 1) #in_features = 8dim, out_features=1dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "offshore-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "attractive-massage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([-1.1431e+02,  3.4190e+01,  1.5000e+01,  5.6120e+03,  1.2830e+03,\n",
      "         1.0150e+03,  4.7200e+02,  1.4936e+00])\n",
      "output:  tensor([1508.0210], grad_fn=<SelectBackward>)\n",
      "target:  tensor([66900.])\n",
      "epoch 0, loss 56049602560.0\n",
      "---------------------------------------------\n",
      "input:  tensor([-1.1431e+02,  3.4190e+01,  1.5000e+01,  5.6120e+03,  1.2830e+03,\n",
      "         1.0150e+03,  4.7200e+02,  1.4936e+00])\n",
      "output:  tensor([7.4670e+10], grad_fn=<SelectBackward>)\n",
      "target:  tensor([66900.])\n",
      "epoch 1, loss 2.7698533824213035e+21\n",
      "---------------------------------------------\n",
      "input:  tensor([-1.1431e+02,  3.4190e+01,  1.5000e+01,  5.6120e+03,  1.2830e+03,\n",
      "         1.0150e+03,  4.7200e+02,  1.4936e+00])\n",
      "output:  tensor([-2.3301e+16], grad_fn=<SelectBackward>)\n",
      "target:  tensor([66900.])\n",
      "epoch 2, loss 2.7146369316725845e+32\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    print('input: ', inputs[0])\n",
    "    outputs = model(inputs)\n",
    "    print('output: ', outputs[0])\n",
    "    print('target: ', targets[0])\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, targets)\n",
    "    #print(loss)\n",
    "        \n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-gilbert",
   "metadata": {},
   "source": [
    "### Categorical Cross-Entropy Loss \n",
    "\n",
    "Categorical-cross Entropy loss es usualmente aplicado en problemas de clasificación multi clase donde el output del modelo es interpretado como la probabilidad de que un dato pertenezca a una clase.\n",
    "\n",
    "<img src=\"images.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "naughty-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3731, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "outputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch.tensor([1, 0, 3], dtype=torch.int64)\n",
    "loss = ce_loss(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "initial-fusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9297,  0.6877,  1.7151,  0.8076, -0.9618], grad_fn=<SelectBackward>)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0])\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "female-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#To-do: cuenta manual\n",
    "# Cuenta propia para ver cómo funciona\n",
    "\n",
    "result = torch.zeros(5)\n",
    "for i in zip(targets, outputs):\n",
    "    result += i[0] * torch.log(i[1])\n",
    "    \n",
    "sum_res = torch.sum(result)\n",
    "print(sum_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-recording",
   "metadata": {},
   "source": [
    "### Clasificación Multi Clase con MNIST dataset (default available in colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "indian-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
      "0    6    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    5    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "2    7    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    9    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "4    5    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   779  780  781  782  783  784  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "length columns:  785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 300, 784)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./mnist_train_small.csv', header=None, index_col=None)\n",
    "print(train_df.head())\n",
    "print('length columns: ', len(train_df.columns)) #28px x 28px = 784 + label = 1 --> 785 columns\n",
    "train_df.columns[0], train_df.columns[300], train_df.columns[784] #??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "assigned-stockholm",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 784), (20000,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs, labels\n",
    "# Convert from Pandas dataframe to numpy arrays\n",
    "inputs = train_df.drop([0], axis=1).to_numpy()  \n",
    "labels = train_df[0].to_numpy()\n",
    "inputs.shape, labels_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "first-priest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7, 8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_col[0], labels_col[18], labels_col[1880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "central-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "inputs = inputs.float()\n",
    "labels = torch.from_numpy(labels)\n",
    "labels = labels.type(torch.LongTensor) #la función cross-entropy espera un valor representando la categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sublime-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Classification, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "pregnant-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classification(784,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "regular-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "double-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  tensor(6)\n",
      "epoch 0, loss 2.3924241065979004\n",
      "---------------------------------------------\n",
      "labels:  tensor(6)\n",
      "epoch 1, loss 2.302994966506958\n",
      "---------------------------------------------\n",
      "labels:  tensor(6)\n",
      "epoch 2, loss 2.241755962371826\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    #print('input: ', inputs[0])\n",
    "    outputs = model(inputs)\n",
    "    print('labels: ', labels[0])\n",
    "    loss_outputs = torch.sigmoid(outputs)\n",
    "    #print('output: ', loss_outputs)\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(loss_outputs, labels)\n",
    "    #print(loss)\n",
    "        \n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-server",
   "metadata": {},
   "source": [
    "### Binary Cross-Entropy Loss (binary classification, and multilabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-applicant",
   "metadata": {},
   "source": [
    "### Combining Loss Functions for Multi Task Learning problems\n",
    "\n",
    "\n",
    "<img src=\"Diet.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
